{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bf3787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version: 4.0.1\n"
     ]
    }
   ],
   "source": [
    "import sys # system functions (ie. exiting the program)\n",
    "import os # operating system functions (ie. path building on Windows vs. MacOs)\n",
    "import time # for time operations\n",
    "import uuid # for generating unique file names\n",
    "import math # math functions\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display as ipydisplay, Image, clear_output, HTML # for interacting with the notebook better\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "print('OpenCV Version: {}.{}.{}'.format(major_ver, minor_ver, subminor_ver))\n",
    "\n",
    "import numpy as np # matrix operations (ie. difference between two matricies)\n",
    "import cv2 # (OpenCV) computer vision functions (ie. tracking)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt # (optional) for plotting and showing images inline\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1593bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_model = tf.keras.models.load_model(\"upvsdown2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfded41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    }
   ],
   "source": [
    "classes = {\n",
    "    0: 'down',\n",
    "    1: 'up',\n",
    "}\n",
    "\n",
    "\n",
    "# Helper function for applying a mask to an array\n",
    "def mask_array(array, imask):\n",
    "    if array.shape[:2] != imask.shape:\n",
    "        raise Exception(\"Shapes of input and imask are incompatible\")\n",
    "    output = np.zeros_like(array, dtype=np.uint8)\n",
    "    for i, row in enumerate(imask):\n",
    "        output[i, row] = array[i, row]\n",
    "    return output\n",
    "\n",
    "\n",
    "# Begin capturing video\n",
    "video = cv2.VideoCapture(0)\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# Read first frame\n",
    "ok, frame = video.read()\n",
    "if not ok:\n",
    "    print(\"Cannot read video\")\n",
    "    sys.exit()\n",
    "# Use the first frame as an initial background frame\n",
    "bg = frame.copy()\n",
    "\n",
    "\n",
    "# Kernel for erosion and dilation of masks\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "\n",
    "# Display positions (pixel coordinates)\n",
    "positions = {\n",
    "    'hand_pose': (15, 40), # hand pose text\n",
    "    'null_pos': (200, 200) # used as null point for mouse control\n",
    "}\n",
    "\n",
    "\n",
    "# Tracking\n",
    "# Bounding box -> (TopRightX, TopRightY, Width, Height)\n",
    "bbox_initial = (116, 116, 170, 170) # Starting position for bounding box\n",
    "bbox = bbox_initial\n",
    "# Tracking status, -1 for not tracking, 0 for unsuccessful tracking, 1 for successful tracking\n",
    "tracking = -1\n",
    "\n",
    "\n",
    "# Capture, process, display loop    \n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ok, frame = video.read()\n",
    "    display = frame.copy()\n",
    "    data_display = np.zeros_like(display, dtype=np.uint8) # Black screen to display data\n",
    "    if not ok:\n",
    "        break\n",
    "        \n",
    "\n",
    "    \n",
    "    # Processing\n",
    "    # First find the absolute difference between the two images\n",
    "    diff = cv2.absdiff(bg, frame)\n",
    "    mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    # Threshold the mask\n",
    "    th, thresh = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "    # Opening, closing and dilation\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    \n",
    "    img_dilation = cv2.dilate(closing, kernel, iterations=2)\n",
    "    # Get mask indexes\n",
    "    imask = img_dilation > 0\n",
    "    # Get foreground from mask\n",
    "    foreground = mask_array(frame, imask)\n",
    "    foreground_display = foreground.copy()\n",
    "    \n",
    "    \n",
    "    # If tracking is active, update the tracker\n",
    "    if tracking != -1:\n",
    "        tracking, bbox = tracker.update(foreground)\n",
    "        tracking = int(tracking)\n",
    "        \n",
    "        \n",
    "    # Use numpy array indexing to crop the foreground frame\n",
    "    \n",
    "    try:\n",
    "        # Resize cropped hand and make prediction on gesture\n",
    "        hand_crop_resized = np.expand_dims(cv2.resize(display, (110, 110)), axis=0).reshape((1, 110, 110, 1))\n",
    "        prediction = hand_model.predict(hand_crop_resized)\n",
    "        predi = prediction[0].argmax() # Get the index of the greatest confidence\n",
    "        gesture = classes[predi]\n",
    "        \n",
    "        for i, pred in enumerate(prediction[0]):\n",
    "            # Draw confidence bar for each gesture\n",
    "            barx = positions['hand_pose'][0]\n",
    "            bary = 60 + i*60\n",
    "            bar_height = 20\n",
    "            bar_length = int(400 * pred) + barx # calculate length of confidence bar\n",
    "            \n",
    "            # Make the most confidence prediction green\n",
    "            if i == predi:\n",
    "                colour = (0, 255, 0)\n",
    "            else:\n",
    "                colour = (0, 0, 255)\n",
    "            \n",
    "            cv2.putText(data_display, \"{}: {}\".format(classes[i], pred), (positions['hand_pose'][0], 30 + i*60), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "            cv2.rectangle(data_display, (barx, bary), (bar_length, bary - bar_height), colour, -1, 1)\n",
    "        \n",
    "        cv2.putText(display, \"hand pose: {}\".format(gesture), positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        cv2.putText(foreground_display, \"hand pose: {}\".format(gesture), positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    except Exception as ex:\n",
    "        cv2.putText(display, \"hand pose: error\", positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        cv2.putText(foreground_display, \"hand pose: error\", positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    \n",
    "        \n",
    "   \n",
    "    \n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(\"display\", display)\n",
    "    # Display result\n",
    "    cv2.imshow(\"data\", data_display)\n",
    "    \n",
    "    try:\n",
    "        # Display hand_crop\n",
    "        cv2.imshow(\"hand_crop\", hand_crop)\n",
    "    except:\n",
    "        pass\n",
    "    # Display foreground_display\n",
    "    cv2.imshow(\"foreground_display\", foreground_display)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    if k == 27: break # ESC pressed\n",
    "    elif k == 114 or k == 108: \n",
    "        # r pressed\n",
    "        bg = frame.copy()\n",
    "        bbox = bbox_initial\n",
    "        tracking = -1\n",
    "    elif k == 116:\n",
    "        # t pressed\n",
    "        # Initialize tracker with first frame and bounding box\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "        tracking = tracker.init(frame, bbox)\n",
    "    elif k == 115:\n",
    "        # s pressed\n",
    "        fname = os.path.join(\"data\", CURR_POS, \"{}_{}.jpg\".format(CURR_POS, get_unique_name(os.path.join(\"data\", CURR_POS))))\n",
    "        cv2.imwrite(fname, hand_crop)\n",
    "    elif k != 255: print(k)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51856483",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
